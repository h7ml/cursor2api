#!/usr/bin/env python3
"""
æµ‹è¯•æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹
"""
import requests
import json
import time
import os
import sys

# APIé…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼
API_URL = os.getenv("API_URL", "http://127.0.0.1:8001")
API_KEY = os.getenv("API_KEY", "your-secure-api-key-here")

# æ£€æŸ¥ API å¯†é’¥
if not API_KEY or API_KEY == "your-api-key-here":
    print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®ç¯å¢ƒå˜é‡ API_KEY")
    print("   ä¾‹å¦‚ï¼šexport API_KEY=your-actual-api-key")
    sys.exit(1)

# æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹
MODELS = [
    "gpt-5",
    "gpt-5-codex",
    "gpt-5-mini",
    "gpt-5-nano",
    "gpt-4.1",
    "gpt-4o",
    "claude-3.5-sonnet",
    "claude-3.5-haiku",
    "claude-3.7-sonnet",
    "claude-4-sonnet",
    "claude-4-opus",
    "claude-4.1-opus",
    "gemini-2.5-pro",
    "gemini-2.5-flash",
    "o3",
    "o4-mini",
    "deepseek-r1",
    "deepseek-v3.1",
    "kimi-k2-instruct",
    "grok-3",
    "grok-3-mini",
    "grok-4",
    "code-supernova-1-million"
]

def test_models_endpoint():
    """æµ‹è¯•æ¨¡å‹åˆ—è¡¨ç«¯ç‚¹"""
    print("=" * 60)
    print("æµ‹è¯• /v1/models ç«¯ç‚¹")
    print("=" * 60)
    
    headers = {
        "Authorization": f"Bearer {API_KEY}"
    }
    
    try:
        response = requests.get(f"{API_URL}/v1/models", headers=headers)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… æˆåŠŸè·å–æ¨¡å‹åˆ—è¡¨")
            print(f"ğŸ“Š æ¨¡å‹æ•°é‡: {len(data['data'])}")
            print(f"ğŸ“‹ å‰5ä¸ªæ¨¡å‹:")
            for model in data['data'][:5]:
                print(f"   - {model['id']}")
            print(f"   ... å…± {len(data['data'])} ä¸ªæ¨¡å‹")
            return True
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            print(response.text)
            return False
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return False

def test_chat_completion(model_name, test_message):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹çš„èŠå¤©å®Œæˆ"""
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": model_name,
        "messages": [
            {"role": "user", "content": test_message}
        ],
        "stream": False,
        "max_tokens": 100
    }
    
    try:
        response = requests.post(
            f"{API_URL}/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=10
        )
        
        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content']
            # æˆªå–å‰100ä¸ªå­—ç¬¦
            preview = content[:100] + "..." if len(content) > 100 else content
            print(f"âœ… {model_name:30} | å“åº”: {preview}")
            return True
        else:
            print(f"âŒ {model_name:30} | é”™è¯¯: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ {model_name:30} | å¼‚å¸¸: {str(e)[:50]}")
        return False

def test_all_models():
    """æµ‹è¯•æ‰€æœ‰æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ‰€æœ‰æ¨¡å‹çš„èŠå¤©å®ŒæˆåŠŸèƒ½")
    print("=" * 60)
    
    success_count = 0
    failed_count = 0
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„æ¶ˆæ¯
    test_messages = [
        "Hello, what model are you?",
        "å†™ä¸€æ®µPythonä»£ç ",
        "Explain quantum computing",
    ]
    
    for i, model in enumerate(MODELS, 1):
        # ä½¿ç”¨è½®æ¢çš„æµ‹è¯•æ¶ˆæ¯
        test_msg = test_messages[i % len(test_messages)]
        print(f"\n[{i}/{len(MODELS)}] æµ‹è¯•æ¨¡å‹: {model}")
        
        if test_chat_completion(model, test_msg):
            success_count += 1
        else:
            failed_count += 1
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(0.5)
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    print(f"âœ… æˆåŠŸ: {success_count}/{len(MODELS)}")
    print(f"âŒ å¤±è´¥: {failed_count}/{len(MODELS)}")
    print(f"ğŸ“Š æˆåŠŸç‡: {(success_count/len(MODELS)*100):.1f}%")

def test_stream_response():
    """æµ‹è¯•æµå¼å“åº”"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æµå¼å“åº” (ä½¿ç”¨ gpt-5 æ¨¡å‹)")
    print("=" * 60)
    
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "gpt-5",
        "messages": [
            {"role": "user", "content": "Count from 1 to 5"}
        ],
        "stream": True
    }
    
    try:
        response = requests.post(
            f"{API_URL}/v1/chat/completions",
            headers=headers,
            json=payload,
            stream=True,
            timeout=10
        )
        
        if response.status_code == 200:
            print("âœ… æµå¼å“åº”æˆåŠŸï¼Œæ¥æ”¶åˆ°çš„æ•°æ®å—:")
            chunk_count = 0
            for line in response.iter_lines():
                if line:
                    chunk_count += 1
                    line_str = line.decode('utf-8')
                    if chunk_count <= 3:
                        print(f"   å— {chunk_count}: {line_str[:100]}...")
            print(f"   ... å…±æ¥æ”¶ {chunk_count} ä¸ªæ•°æ®å—")
            return True
        else:
            print(f"âŒ æµå¼å“åº”å¤±è´¥: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ æµå¼å“åº”é”™è¯¯: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n")
    print("ğŸš€ " + "=" * 58)
    print("   Advanced AI Models API - å®Œæ•´æµ‹è¯•")
    print("   API URL: " + API_URL)
    print("   æ¨¡å‹æ€»æ•°: " + str(len(MODELS)))
    print("=" * 60)
    
    # 1. æµ‹è¯•æ¨¡å‹åˆ—è¡¨
    models_ok = test_models_endpoint()
    
    # 2. æµ‹è¯•æ‰€æœ‰æ¨¡å‹
    if models_ok:
        test_all_models()
    
    # 3. æµ‹è¯•æµå¼å“åº”
    test_stream_response()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)

if __name__ == "__main__":
    main()