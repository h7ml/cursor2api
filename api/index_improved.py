
"""
Vercel Serverless Function - æ”¹è¿›çš„ AI API æœåŠ¡
ä½¿ç”¨å¤šç§ AI æœåŠ¡æä¾›çœŸæ­£çš„æ™ºèƒ½å“åº”
"""
import json
import time
import random
import string
import os
import requests
from http.server import BaseHTTPRequestHandler

# é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
API_KEY = os.environ.get('API_KEY', 'sk-default-key-please-change')

# ä½¿ç”¨å…è´¹æˆ–æ˜“è·å–çš„ AI æœåŠ¡
# 1. HuggingFace Inference API (å…è´¹ï¼Œæœ‰é™é¢)
HUGGINGFACE_API_KEY = os.environ.get('HUGGINGFACE_API_KEY', '')

# 2. Cohere API (æœ‰å…è´¹é¢åº¦)
COHERE_API_KEY = os.environ.get('COHERE_API_KEY', '')

# 3. Together AI (æœ‰å…è´¹è¯•ç”¨)
TOGETHER_API_KEY = os.environ.get('TOGETHER_API_KEY', '')

# 4. DeepInfra (æœ‰å…è´¹é¢åº¦)
DEEPINFRA_API_KEY = os.environ.get('DEEPINFRA_API_KEY', '')

# 5. ä½¿ç”¨ç¬¬ä¸‰æ–¹ä»£ç†æœåŠ¡
PROXY_URL = os.environ.get('PROXY_URL', '')  # å¦‚: https://api.openai-proxy.com
PROXY_API_KEY = os.environ.get('PROXY_API_KEY', '')

# æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
SUPPORTED_MODELS = [
    "gpt-3.5-turbo",
    "gpt-4",
    "gpt-4o",
    "claude-3-opus",
    "claude-3-sonnet",
    "claude-3-haiku",
    "claude-3.5-sonnet",
    "claude-4-opus",
    "claude-4.1-opus",
    "llama-2-70b",
    "llama-3-70b",
    "mixtral-8x7b",
    "deepseek-chat",
    "qwen-72b",
    "yi-34b",
]

def generate_random_string(length):
    """ç”Ÿæˆéšæœºå­—ç¬¦ä¸²"""
    return ''.join(random.choices(string.ascii_lowercase + string.digits, k=length))

def get_html_content():
    """è·å–æ¬¢è¿é¡µé¢HTMLå†…å®¹"""
    models_badges = ''.join([f'<div class="model-badge">{model}</div>' for model in SUPPORTED_MODELS])
    
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>AI API Proxy Service</title>
        <meta charset="UTF-8">
        <style>
            * {{ margin: 0; padding: 0; box-sizing: border-box; }}
            body {{ 
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
                padding: 20px;
            }}
            .container {{
                max-width: 1200px;
                margin: 0 auto;
                background: white;
                border-radius: 20px;
                padding: 40px;
                box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            }}
            h1 {{ 
                color: #333; 
                border-bottom: 3px solid #667eea;
                padding-bottom: 15px;
                margin-bottom: 30px;
            }}
            .info {{ 
                background: #f8f9fa; 
                padding: 20px; 
                border-radius: 10px; 
                margin: 20px 0;
                border-left: 4px solid #667eea;
            }}
            .models-grid {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                gap: 10px;
                margin: 20px 0;
            }}
            .model-badge {{
                background: linear-gradient(135deg, #667eea, #764ba2);
                color: white;
                padding: 8px 12px;
                border-radius: 8px;
                font-size: 0.9em;
                text-align: center;
                font-weight: 500;
            }}
            .status {{
                display: inline-block;
                padding: 5px 12px;
                background: #28a745;
                color: white;
                border-radius: 20px;
                font-weight: bold;
            }}
            code {{
                background: #e9ecef;
                padding: 3px 8px;
                border-radius: 4px;
                font-family: 'Courier New', monospace;
            }}
            pre {{
                background: #2d3436;
                color: #dfe6e9;
                padding: 15px;
                border-radius: 8px;
                overflow-x: auto;
                margin: 10px 0;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸš€ AI API Proxy Service</h1>
            
            <div class="info">
                <p><strong>çŠ¶æ€:</strong> <span class="status">è¿è¡Œä¸­</span></p>
                <p><strong>ç‰ˆæœ¬:</strong> v2.0 - çœŸå® AI å“åº”</p>
                <p><strong>åŸºç¡€URL:</strong> <code>https://api.autoschool.eu.org</code></p>
                <p><strong>APIå¯†é’¥:</strong> <code>{'å·²é…ç½®' if API_KEY != 'sk-default-key-please-change' else 'éœ€è¦é…ç½®'}</code></p>
            </div>
            
            <div class="info">
                <h2>ğŸ¤– æ”¯æŒçš„æ¨¡å‹</h2>
                <div class="models-grid">
                    {models_badges}
                </div>
            </div>
            
            <div class="info">
                <h3>ğŸ“¡ API ä½¿ç”¨ç¤ºä¾‹</h3>
                <pre>curl -X POST "https://api.autoschool.eu.org/v1/chat/completions" \\
  -H "Authorization: Bearer YOUR_API_KEY" \\
  -H "Content-Type: application/json" \\
  -d '{{
    "model": "claude-3.5-sonnet",
    "messages": [{{"role": "user", "content": "99+2=?"}}],
    "stream": false
  }}'</pre>
            </div>
            
            <div class="info">
                <h3>âœ¨ ç‰¹æ€§</h3>
                <ul>
                    <li>âœ… çœŸå® AI å“åº”ï¼ˆä¸æ˜¯æ¨¡æ¿ï¼‰</li>
                    <li>âœ… æ”¯æŒå¤šä¸ª AI æä¾›å•†</li>
                    <li>âœ… OpenAI API æ ¼å¼å…¼å®¹</li>
                    <li>âœ… æ”¯æŒæµå¼å’Œéæµå¼å“åº”</li>
                    <li>âœ… æ™ºèƒ½é™çº§å’Œè´Ÿè½½å‡è¡¡</li>
                </ul>
            </div>
        </div>
    </body>
    </html>
    """

class AIService:
    """AI æœåŠ¡è°ƒç”¨ç±»"""
    
    @staticmethod
    def call_huggingface(messages, model):
        """è°ƒç”¨ HuggingFace Inference API"""
        if not HUGGINGFACE_API_KEY:
            return None
        
        # ä½¿ç”¨ HuggingFace çš„å¼€æºæ¨¡å‹
        hf_models = {
            "llama-2-70b": "meta-llama/Llama-2-70b-chat-hf",
            "mixtral-8x7b": "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "default": "microsoft/DialoGPT-medium"
        }
        
        hf_model = hf_models.get(model, hf_models["default"])
        
        headers = {
            "Authorization": f"Bearer {HUGGINGFACE_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # æ„é€ è¾“å…¥
        user_message = ""
        for msg in messages:
            if msg["role"] == "user":
                user_message = msg["content"]
        
        data = {
            "inputs": user_message,
            "parameters": {
                "max_new_tokens": 200,
                "temperature": 0.7,
                "top_p": 0.95
            }
        }
        
        try:
            response = requests.post(
                f"https://api-inference.huggingface.co/models/{hf_model}",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    return result[0].get("generated_text", "")
                return str(result)
        except Exception as e:
            print(f"HuggingFace API error: {e}")
        
        return None
    
    @staticmethod
    def call_together_ai(messages, model):
        """è°ƒç”¨ Together AI"""
        if not TOGETHER_API_KEY:
            return None
        
        # Together AI æ¨¡å‹æ˜ å°„
        together_models = {
            "llama-2-70b": "meta-llama/Llama-2-70b-chat-hf",
            "llama-3-70b": "meta-llama/Meta-Llama-3-70B-Instruct",
            "mixtral-8x7b": "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "qwen-72b": "Qwen/Qwen1.5-72B-Chat",
            "yi-34b": "zero-one-ai/Yi-34B-Chat",
            "default": "meta-llama/Llama-2-7b-chat-hf"
        }
        
        actual_model = together_models.get(model, together_models["default"])
        
        headers = {
            "Authorization": f"Bearer {TOGETHER_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": actual_model,
            "messages": messages,
            "max_tokens": 512,
            "temperature": 0.7,
            "top_p": 0.7,
            "top_k": 50,
            "stream": False
        }
        
        try:
            response = requests.post(
                "https://api.together.xyz/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result
        except Exception as e:
            print(f"Together AI error: {e}")
        
        return None
    
    @staticmethod
    def call_deepinfra(messages, model):
        """è°ƒç”¨ DeepInfra API"""
        if not DEEPINFRA_API_KEY:
            return None
        
        # DeepInfra æ¨¡å‹æ˜ å°„
        deepinfra_models = {
            "llama-2-70b": "meta-llama/Llama-2-70b-chat-hf",
            "mixtral-8x7b": "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "qwen-72b": "Qwen/Qwen2-72B-Instruct",
            "yi-34b": "01-ai/Yi-34B-Chat",
            "default": "meta-llama/Llama-2-7b-chat-hf"
        }
        
        actual_model = deepinfra_models.get(model, deepinfra_models["default"])
        
        headers = 