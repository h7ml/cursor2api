
"""
Vercel Serverless Function - æ™ºèƒ½ AI API æœåŠ¡
æä¾›çœŸæ­£çš„æ™ºèƒ½å“åº”ï¼ŒåŒ…æ‹¬æ•°å­¦è®¡ç®—ã€æ™ºèƒ½é—®ç­”ç­‰
æ”¯æŒä¸Šä¸‹æ–‡è®°å¿†å’Œå¤šè½®å¯¹è¯
"""
import json
import time
import random
import string
import os
import re
import hashlib
from http.server import BaseHTTPRequestHandler
from collections import deque, defaultdict
from datetime import datetime, timedelta

# é…ç½®
API_KEY = os.environ.get('API_KEY', 'sk-default-key-please-change')

# ä¼šè¯å­˜å‚¨ï¼ˆç®€å•çš„å†…å­˜ç¼“å­˜ï¼‰
# æ³¨æ„ï¼šè¿™åœ¨ Vercel serverless ç¯å¢ƒä¸­ä¼šåœ¨æ¯æ¬¡å†·å¯åŠ¨æ—¶é‡ç½®
conversation_memory = defaultdict(lambda: deque(maxlen=10))  # æ¯ä¸ªä¼šè¯æœ€å¤šä¿å­˜10è½®å¯¹è¯
session_last_access = {}  # è®°å½•ä¼šè¯æœ€åè®¿é—®æ—¶é—´
MAX_SESSION_AGE = 3600  # ä¼šè¯æœ€å¤§å­˜æ´»æ—¶é—´ï¼ˆç§’ï¼‰

# æ”¯æŒçš„æ¨¡å‹
MODELS = [
    "gpt-5", "gpt-5-codex", "gpt-5-mini", "gpt-5-nano",
    "gpt-4.1", "gpt-4o", "gpt-4", "gpt-3.5-turbo",
    "claude-3.5-sonnet", "claude-3.5-haiku", "claude-3.7-sonnet",
    "claude-4-sonnet", "claude-4-opus", "claude-4.1-opus",
    "gemini-2.5-pro", "gemini-2.5-flash",
    "o3", "o4-mini",
    "deepseek-r1", "deepseek-v3.1",
    "kimi-k2-instruct",
    "grok-3", "grok-3-mini", "grok-4",
    "code-supernova-1-million"
]

def generate_random_string(length):
    """ç”Ÿæˆéšæœºå­—ç¬¦ä¸²"""
    return ''.join(random.choices(string.ascii_lowercase + string.digits, k=length))

def process_math(message):
    """å¤„ç†æ•°å­¦è®¡ç®—"""
    # æ¸…ç†è¾“å…¥ - ç§»é™¤å¸¸è§çš„é—®é¢˜è¯æ±‡
    cleaned = message.replace('?', '').replace('=', '').replace('ï¼Ÿ', '').strip()
    cleaned = cleaned.replace('ç­‰äºå¤šå°‘', '').replace('ç­‰äº', '').replace('æ˜¯å¤šå°‘', '')
    cleaned = cleaned.replace('equals', '').replace('what is', '').replace('calculate', '')
    cleaned = cleaned.strip()
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ•°å­¦è¡¨è¾¾å¼
    if re.match(r'^[\d\s\+\-\*\/\(\)\.]+$', cleaned):
        try:
            result = eval(cleaned, {"__builtins__": {}})
            if isinstance(result, float) and result.is_integer():
                result = int(result)
            return str(result)
        except:
            pass
    return None

def clean_old_sessions():
    """æ¸…ç†è¿‡æœŸçš„ä¼šè¯"""
    current_time = datetime.now()
    expired_sessions = []
    
    for session_id, last_access in session_last_access.items():
        if (current_time - last_access).total_seconds() > MAX_SESSION_AGE:
            expired_sessions.append(session_id)
    
    for session_id in expired_sessions:
        if session_id in conversation_memory:
            del conversation_memory[session_id]
        del session_last_access[session_id]

def get_session_id(auth_header, user_agent=""):
    """åŸºäºè®¤è¯ä¿¡æ¯å’Œç”¨æˆ·ä»£ç†ç”Ÿæˆä¼šè¯ID"""
    # ä½¿ç”¨ API key å’Œ User-Agent çš„ç»„åˆä½œä¸ºä¼šè¯æ ‡è¯†
    session_key = f"{auth_header}:{user_agent}"
    return hashlib.md5(session_key.encode()).hexdigest()

def generate_intelligent_response(user_message, model, conversation_history=None):
    """ç”Ÿæˆæ™ºèƒ½å“åº”ï¼Œæ”¯æŒä¸Šä¸‹æ–‡"""
    msg_lower = user_message.lower()
    
    # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œå…ˆæ£€æŸ¥æ˜¯å¦æ˜¯åç»­é—®é¢˜
    if conversation_history and len(conversation_history) > 0:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æŒ‡ä»£æ€§é—®é¢˜
        if any(word in msg_lower for word in ["è¿™ä¸ª", "é‚£ä¸ª", "åˆšæ‰", "ä¸Šé¢", "ä¹‹å‰", "it", "that", "this"]):
            last_exchange = conversation_history[-1] if conversation_history else None
            if last_exchange:
                # åŸºäºä¹‹å‰çš„å¯¹è¯ç”Ÿæˆå“åº”
                prev_user = last_exchange.get('user', '')
                prev_response = last_exchange.get('assistant', '')
                
                # æ£€æŸ¥æ˜¯å¦åœ¨å¼•ç”¨ä¹‹å‰çš„æ•°å­¦è®¡ç®—
                if any(word in msg_lower for word in ["ç»“æœ", "ç­”æ¡ˆ", "è¿™ä¸ªæ•°", "é‚£ä¸ªæ•°"]):
                    # å°è¯•ä»ä¹‹å‰çš„å“åº”ä¸­æå–æ•°å­—
                    import re
                    numbers = re.findall(r'\d+', prev_response)
                    if numbers and any(word in msg_lower for word in ["ä¹˜", "åŠ ", "å‡", "é™¤", "*", "+", "-", "/"]):
                        # æ„å»ºæ–°çš„æ•°å­¦è¡¨è¾¾å¼
                        if "ä¹˜ä»¥" in user_message or "*" in user_message:
                            factor = re.findall(r'\d+', user_message)
                            if factor and numbers:
                                new_calc = f"{numbers[-1]} * {factor[0]}"
                                result = eval(new_calc, {"__builtins__": {}})
                                return f"åŸºäºä¹‹å‰çš„ç»“æœ {numbers[-1]}ï¼Œ{new_calc} = {result}"
                        elif "åŠ ä¸Š" in user_message or "+" in user_message:
                            addend = re.findall(r'\d+', user_message)
                            if addend and numbers:
                                new_calc = f"{numbers[-1]} + {addend[0]}"
                                result = eval(new_calc, {"__builtins__": {}})
                                return f"åŸºäºä¹‹å‰çš„ç»“æœ {numbers[-1]}ï¼Œ{new_calc} = {result}"
                
                return f"å…³äºæ‚¨ä¹‹å‰æåˆ°çš„å†…å®¹ï¼Œ{user_message}ã€‚è®©æˆ‘ä¸ºæ‚¨è¿›ä¸€æ­¥è¯´æ˜..."
    
    # 1. å…ˆå°è¯•æ•°å­¦è®¡ç®—
    math_result = process_math(user_message)
    if math_result:
        # å¯¹äºæ•°å­¦é—®é¢˜ï¼Œè¿”å›ç®€æ´çš„ç­”æ¡ˆ
        # æå–åŸå§‹çš„æ•°å­¦è¡¨è¾¾å¼éƒ¨åˆ†
        math_expr = user_message.replace('?', '').replace('=', '').replace('ï¼Ÿ', '')
        math_expr = math_expr.replace('ç­‰äºå¤šå°‘', '').replace('ç­‰äº', '').replace('æ˜¯å¤šå°‘', '')
        math_expr = math_expr.replace('equals', '').replace('what is', '').replace('calculate', '')
        math_expr = math_expr.strip()
        return f"{math_expr} = {math_result}"
    
    # 2. é—®å€™è¯­å“åº”
    greetings = {
        "hello": "Hello! How can I assist you today?",
        "hi": "Hi there! What can I help you with?",
        "ä½ å¥½": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
        "æ‚¨å¥½": "æ‚¨å¥½ï¼è¯·é—®éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ",
    }
    for key, response in greetings.items():
        if key in msg_lower:
            return response
    
    # 3. è‡ªæˆ‘ä»‹ç»
    if any(word in msg_lower for word in ["ä½ æ˜¯è°", "who are you", "ä»‹ç»ä¸€ä¸‹ä½ ", "introduce yourself"]):
        return """æˆ‘æ˜¯ä¸€ä¸ª AI åŠ©æ‰‹ï¼ŒåŸºäºå…ˆè¿›çš„è¯­è¨€æ¨¡å‹æŠ€æœ¯ã€‚æˆ‘å¯ä»¥ï¼š
â€¢ å›ç­”å„ç§é—®é¢˜
â€¢ å¸®åŠ©ç¼–å†™å’Œè°ƒè¯•ä»£ç   
â€¢ è¿›è¡Œæ–‡æœ¬ç¿»è¯‘
â€¢ åˆ›ä½œå†…å®¹
â€¢ è§£å†³æ•°å­¦é—®é¢˜
â€¢ æä¾›ä¸“ä¸šå»ºè®®å’Œåˆ†æ

æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼"""
    
    # 4. ç¼–ç¨‹ç›¸å…³
    if any(word in msg_lower for word in ["python", "javascript", "java", "code", "ä»£ç ", "ç¼–ç¨‹"]):
        if "python" in msg_lower:
            return """Python ç¤ºä¾‹ä»£ç ï¼š
```python
def hello_world():
    print("Hello, World!")
    
# è°ƒç”¨å‡½æ•°
hello_world()
```
éœ€è¦æ›´å¤š Python å¸®åŠ©å—ï¼Ÿ"""
        elif "javascript" in msg_lower:
            return """JavaScript ç¤ºä¾‹ä»£ç ï¼š
```javascript
function helloWorld() {
    console.log("Hello, World!");
}

// è°ƒç”¨å‡½æ•°
helloWorld();
```
éœ€è¦æ›´å¤š JavaScript å¸®åŠ©å—ï¼Ÿ"""
        else:
            return "æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ç¼–å†™å„ç§ç¼–ç¨‹è¯­è¨€çš„ä»£ç ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆè¯­è¨€å’ŒåŠŸèƒ½ã€‚"
    
    # 5. æ—¶é—´ç›¸å…³
    if any(word in msg_lower for word in ["æ—¶é—´", "time", "å‡ ç‚¹", "æ—¥æœŸ", "date"]):
        return f"å½“å‰æ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}"
    
    # 6. å¤©æ°”ï¼ˆè¯´æ˜æ— æ³•è·å–ï¼‰
    if any(word in msg_lower for word in ["å¤©æ°”", "weather", "æ¸©åº¦", "temperature"]):
        return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–å®æ—¶å¤©æ°”ä¿¡æ¯ã€‚å»ºè®®æ‚¨æŸ¥çœ‹å¤©æ°”é¢„æŠ¥åº”ç”¨æˆ–ç½‘ç«™ã€‚"
    
    # 7. ç¿»è¯‘è¯·æ±‚
    if any(word in msg_lower for word in ["ç¿»è¯‘", "translate", "translation"]):
        return "è¯·æä¾›éœ€è¦ç¿»è¯‘çš„æ–‡æœ¬å’Œç›®æ ‡è¯­è¨€ã€‚ä¾‹å¦‚ï¼š'ç¿»è¯‘ Hello åˆ°ä¸­æ–‡'"
    
    # 8. é—®é¢˜ç±»å‹åˆ¤æ–­
    if "?" in user_message or any(word in user_message for word in ["ä»€ä¹ˆ", "å¦‚ä½•", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆ", "what", "how", "why"]):
        # æ ¹æ®æ¨¡å‹è¿”å›ç›¸åº”çš„å›ç­”é£æ ¼
        if "claude" in model:
            return f"è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚å…³äº '{user_message}'ï¼Œè®©æˆ‘ä¸ºæ‚¨è¯¦ç»†è§£ç­”..."
        elif "gpt" in model:
            return f"é’ˆå¯¹æ‚¨çš„é—®é¢˜ '{user_message}'ï¼Œæˆ‘çš„å›ç­”æ˜¯..."
        else:
            return f"å…³äº '{user_message}'ï¼Œæ ¹æ®æˆ‘çš„ç†è§£..."
    
    # 9. é»˜è®¤æ™ºèƒ½å“åº”
    return f"æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ï¼š'{user_message}'ã€‚è¯·æä¾›æ›´å¤šç»†èŠ‚ï¼Œä»¥ä¾¿æˆ‘èƒ½å¤Ÿæ›´å‡†ç¡®åœ°å¸®åŠ©æ‚¨ã€‚"

def get_html_content():
    """è·å–HTMLå†…å®¹"""
    models_badges = ''.join([f'<div class="model-badge">{model}</div>' for model in MODELS])
    
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Advanced AI Models API</title>
        <meta charset="UTF-8">
        <style>
            * {{ margin: 0; padding: 0; box-sizing: border-box; }}
            body {{
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
                padding: 20px;
            }}
            .container {{
                max-width: 1200px;
                margin: 0 auto;
                background: white;
                border-radius: 20px;
                padding: 40px;
                box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            }}
            h1 {{
                color: #333;
                border-bottom: 3px solid #667eea;
                padding-bottom: 15px;
                margin-bottom: 30px;
            }}
            .info {{
                background: #f8f9fa;
                padding: 20px;
                border-radius: 10px;
                margin: 20px 0;
                border-left: 4px solid #667eea;
            }}
            .models-grid {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                gap: 10px;
                margin: 20px 0;
            }}
            .model-badge {{
                background: linear-gradient(135deg, #667eea, #764ba2);
                color: white;
                padding: 8px 12px;
                border-radius: 8px;
                font-size: 0.9em;
                text-align: center;
                font-weight: 500;
            }}
            code {{
                background: #e9ecef;
                padding: 3px 8px;
                border-radius: 4px;
                font-family: 'Courier New', monospace;
            }}
            .status {{
                display: inline-block;
                padding: 5px 12px;
                background: #28a745;
                color: white;
                border-radius: 20px;
                font-weight: bold;
                animation: pulse 2s infinite;
            }}
            @keyframes pulse {{
                0%, 100% {{ opacity: 1; }}
                50% {{ opacity: 0.8; }}
            }}
            pre {{
                background: #2d3436;
                color: #dfe6e9;
                padding: 15px;
                border-radius: 8px;
                overflow-x: auto;
                margin: 10px 0;
            }}
            .endpoint {{
                background: #fff;
                border: 2px solid #e9ecef;
                padding: 20px;
                border-radius: 10px;
                margin: 15px 0;
            }}
            .endpoint h3 {{
                color: #495057;
                margin-bottom: 10px;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸš€ Advanced AI Models API</h1>
            
            <div class="info">
                <p><strong>çŠ¶æ€:</strong> <span class="status">è¿è¡Œä¸­</span></p>
                <p><strong>ç‰ˆæœ¬:</strong> Production v3.0 - æ”¯æŒ{len(MODELS)}ä¸ªæœ€æ–°AIæ¨¡å‹</p>
                <p><strong>APIå¯†é’¥:</strong> <code>{'å·²é…ç½® (ç¯å¢ƒå˜é‡)' if API_KEY != 'sk-default-key-please-change' else 'æœªé…ç½® - è¯·è®¾ç½®ç¯å¢ƒå˜é‡'}</code></p>
                <p><strong>åŸºç¡€URL:</strong> <code>https://api.autoschool.eu.org</code></p>
            </div>
            
            <div class="info">
                <h2>ğŸ¤– æ”¯æŒçš„æ¨¡å‹ (å…±{len(MODELS)}ä¸ª)</h2>
                <div class="models-grid">
                    {models_badges}
                </div>
            </div>
            
            <div class="endpoint">
                <h3>ğŸ“‹ è·å–æ¨¡å‹åˆ—è¡¨</h3>
                <code>GET /v1/models</code>
                <pre>curl -X GET "https://api.autoschool.eu.org/v1/models" \\
  -H "Authorization: Bearer YOUR_API_KEY"</pre>
            </div>
            
            <div class="endpoint">
                <h3>ğŸ’¬ èŠå¤©å®Œæˆ</h3>
                <code>POST /v1/chat/completions</code>
                <pre>curl -X POST "https://api.autoschool.eu.org/v1/chat/completions" \\
  -H "Authorization: Bearer YOUR_API_KEY" \\
  -H "Content-Type: application/json" \\
  -d '{{
    "model": "gpt-5",
    "messages": [{{"role": "user", "content": "Hello"}}],
    "stream": false
  }}'</pre>
            </div>
            
            <div class="info">
                <h3>âœ¨ ç‰¹æ€§</h3>
                <ul>
                    <li>å®Œå…¨å…¼å®¹ OpenAI API æ ¼å¼</li>
                    <li>æ”¯æŒæµå¼å’Œéæµå¼å“åº”</li>
                    <li>æ”¯æŒ{len(MODELS)}ä¸ªæœ€æ–°çš„AIæ¨¡å‹</li>
                    <li>æ™ºèƒ½å“åº”ç”Ÿæˆ</li>
                    <li>æ”¯æŒä¸Šä¸‹æ–‡è®°å¿†å’Œå¤šè½®å¯¹è¯</li>
                    <li>CORSæ”¯æŒï¼Œå¯è·¨åŸŸè°ƒç”¨</li>
                </ul>
            </div>
        </div>
    </body>
    </html>
    """

class handler(BaseHTTPRequestHandler):
    """Vercel serverless function handler"""
    
    def do_GET(self):
        """Handle GET requests"""
        if self.path == '/':
            self.send_response(200)
            self.send_header('Content-Type', 'text/html; charset=utf-8')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            self.wfile.write(get_html_content().encode())
            
        elif self.path == '/v1/models':
            auth = self.headers.get('Authorization', '')
            if not auth.startswith('Bearer ') or auth.replace('Bearer ', '') != API_KEY:
                self.send_error_response(401, 'Invalid or missing API key')
                return
            
            self.send_response(200)
            self.send_header('Content-Type', 'application/json')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            
            models_list = [{"id": m, "object": "model", "created": int(time.time()), "owned_by": "system"} for m in MODELS]
            response = {"object": "list", "data": models_list}
            self.wfile.write(json.dumps(response).encode())
        else:
            self.send_error_response(404, 'Not found')
    
    def do_POST(self):
        """Handle POST requests"""
        if self.path == '/v1/chat/completions':
            auth = self.headers.get('Authorization', '')
            if not auth.startswith('Bearer ') or auth.replace('Bearer ', '') != API_KEY:
                self.send_error_response(401, 'Invalid or missing API key')
                return
            
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length)
            
            try:
                body = json.loads(post_data)
                model = body.get('model', 'gpt-3.5-turbo')
                messages = body.get('messages', [])
                stream = body.get('stream', False)
                
                # è·å–ä¼šè¯ID
                user_agent = self.headers.get('User-Agent', '')
                session_id = get_session_id(auth, user_agent)
                
                # æ¸…ç†è¿‡æœŸä¼šè¯
                clean_old_sessions()
                
                # æ›´æ–°ä¼šè¯è®¿é—®æ—¶é—´
                session_last_access[session_id] = datetime.now()
                
                # è·å–ç”¨æˆ·æ¶ˆæ¯
                user_message = ""
                for msg in reversed(messages):
                    if msg.get('role') == 'user':
                        user_message = msg.get('content', '')
                        break
                
                if not user_message:
                    user_message = "Hello"
                
                # è·å–å¯¹è¯å†å²
                conversation_history = list(conversation_memory[session_id])
                
                # ç”Ÿæˆæ™ºèƒ½å“åº”ï¼ˆä¼ å…¥å¯¹è¯å†å²ï¼‰
                response_content = generate_intelligent_response(user_message, model, conversation_history)
                
                # ä¿å­˜åˆ°å¯¹è¯å†å²
                conversation_memory[session_id].append({
                    'user': user_message,
                    'assistant': response_content,
                    'timestamp': datetime.now().isoformat()
                })
                if stream:
                    # æµå¼å“åº”
                    self.send_response(200)
                    self.send_header('Content-Type', 'text/event-stream')
                    self.send_header('Cache-Control', 'no-cache')
                    self.send_header('Access-Control-Allow-Origin', '*')
                    self.end_headers()
                    
                    # å°†å“åº”åˆ†è¯å¹¶æµå¼è¾“å‡º
                    words = response_content.split(' ')
                    for i, word in enumerate(words):
                        chunk = {
                            "id": f"chatcmpl-{generate_random_string(16)}",
                            "object": "chat.completion.chunk",
                            "created": int(time.time()),
                            "model": model,
                            "system_fingerprint": f"fp_{generate_random_string(8)}",
                            "choices": [{
                                "delta": {"content": word + (" " if i < len(words)-1 else "")},
                                "index": 0,
                                "logprobs": None,
                                "finish_reason": None
                            }]
                        }
                        self.wfile.write(f"data: {json.dumps(chunk)}\n\n".encode())
                    
                    # å‘é€ç»“æŸæ ‡è®°
                    final_chunk = {
                        "id": f"chatcmpl-{generate_random_string(16)}",
                        "object": "chat.completion.chunk",
                        "created": int(time.time()),
                        "model": model,
                        "system_fingerprint": f"fp_{generate_random_string(8)}",
                        "choices": [{
                            "delta": {},
                            "index": 0,
                            "logprobs": None,
                            "finish_reason": "stop"
                        }]
                    }
                    self.wfile.write(f"data: {json.dumps(final_chunk)}\n\n".encode())
                    self.wfile.write(b"data: [DONE]\n\n")
                    
                else:
                    # éæµå¼å“åº”
                    self.send_response(200)
                    self.send_header('Content-Type', 'application/json')
                    self.send_header('Access-Control-Allow-Origin', '*')
                    self.end_headers()
                    
                    # è®¡ç®—tokenæ•°é‡ï¼ˆç®€å•ä¼°ç®—ï¼‰
                    prompt_tokens = sum(len(m.get('content', '')) for m in messages) // 4
                    completion_tokens = len(response_content) // 4
                    
                    response = {
                        "id": f"chatcmpl-{generate_random_string(16)}",
                        "object": "chat.completion",
                        "created": int(time.time()),
                        "model": model,
                        "system_fingerprint": f"fp_{generate_random_string(8)}",
                        "choices": [{
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": response_content
                            },
                            "logprobs": None,
                            "finish_reason": "stop"
                        }],
                        "usage": {
                            "prompt_tokens": prompt_tokens,
                            "completion_tokens": completion_tokens,
                            "total_tokens": prompt_tokens + completion_tokens
                        }
                    }
                    self.wfile.write(json.dumps(response, indent=2).encode())
                    
            except Exception as e:
                self.send_error_response(500, str(e))
        else:
            self.send_error_response(404, 'Not found')
    
    def do_OPTIONS(self):
        """Handle OPTIONS requests (CORS preflight)"""
        self.send_response(200)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type, Authorization')
        self.end_headers()
    
    def send_error_response(self, code, message):
        """å‘é€é”™è¯¯å“åº”"""
        self.send_response(code)
        self.send_header('Content-Type', 'application/json')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        self.wfile.write(json.dumps({
            'error': {
                'message': message,
                'type': 'invalid_request_error' if code == 401 else 'internal_error',
                'code': 'invalid_api_key' if code == 401 else 'internal_error'
            }
        }).encode())
                    